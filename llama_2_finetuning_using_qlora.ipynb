{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installing Required Libraries\n!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-04T12:17:20.680950Z","iopub.execute_input":"2024-05-04T12:17:20.681405Z","iopub.status.idle":"2024-05-04T12:17:33.142467Z","shell.execute_reply.started":"2024-05-04T12:17:20.681365Z","shell.execute_reply":"2024-05-04T12:17:33.141210Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Loading necessary modules from these libraries.**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:20:31.558819Z","iopub.execute_input":"2024-05-04T12:20:31.559573Z","iopub.status.idle":"2024-05-04T12:20:53.856421Z","shell.execute_reply.started":"2024-05-04T12:20:31.559533Z","shell.execute_reply":"2024-05-04T12:20:53.855431Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-04 12:20:40.622023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-04 12:20:40.622160: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-04 12:20:40.791852: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model from Hugging Face hub\nbase_model = \"NousResearch/Llama-2-7b-chat-hf\"\n\n# New instruction dataset\nguanaco_dataset = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model\nnew_model = \"llama-2-7b-chat-guanaco\"","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:23:23.878008Z","iopub.execute_input":"2024-05-04T12:23:23.878857Z","iopub.status.idle":"2024-05-04T12:23:23.883065Z","shell.execute_reply.started":"2024-05-04T12:23:23.878809Z","shell.execute_reply":"2024-05-04T12:23:23.882165Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Loading Dataset**","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(guanaco_dataset,split='train')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:23:58.956507Z","iopub.execute_input":"2024-05-04T12:23:58.957166Z","iopub.status.idle":"2024-05-04T12:24:00.275163Z","shell.execute_reply.started":"2024-05-04T12:23:58.957130Z","shell.execute_reply":"2024-05-04T12:24:00.274196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#getting attribute float16 from torch module to reduce memory footprint and faster computation\n\ncompute_dtype = getattr(torch,'float16')\n#setting configuration\nquant_config = BitsAndBytesConfig(load_in_4bit=True,\n                                  bnb_4bit_compute_dtype=compute_dtype,\n                                  bnb_4bit_quant_type=\"nf4\",\n                                  bnb_4bit_use_double_quant=False,)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:23:54.129348Z","iopub.execute_input":"2024-05-04T12:23:54.129708Z","iopub.status.idle":"2024-05-04T12:23:54.135879Z","shell.execute_reply.started":"2024-05-04T12:23:54.129677Z","shell.execute_reply":"2024-05-04T12:23:54.134947Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Loading Pretrained Model with Quantized Configuration**","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config = quant_config,\n    device_map ={'':0}  #mapping the entire model to gpu\n)\n\nmodel.config.use_cache = False #We will not use cahe for model output(helps in memory issue)\nmodel.config.pretraining_tp = 1 # parallelism","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:24:12.936848Z","iopub.execute_input":"2024-05-04T12:24:12.937322Z","iopub.status.idle":"2024-05-04T12:26:16.938141Z","shell.execute_reply.started":"2024-05-04T12:24:12.937282Z","shell.execute_reply":"2024-05-04T12:26:16.937224Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c029a43d58a841ab8b00c02ee4d06946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"743919daa5db401e8ccff831d7772c14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a787e4799c3443b9b5963896fc114229"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"062f77f0012c44a8a44dd2b7f92c0a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63ed2318078044c883fd3e37d603a901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c864660ff2a40aab9b2aa9907f76cf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e91f9ff05cae42379718aa7b482f40a3"}},"metadata":{}}]},{"cell_type":"code","source":"device_map ={'':0}","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:13:54.814706Z","iopub.execute_input":"2024-05-04T13:13:54.815713Z","iopub.status.idle":"2024-05-04T13:13:54.819746Z","shell.execute_reply.started":"2024-05-04T13:13:54.815672Z","shell.execute_reply":"2024-05-04T13:13:54.818763Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Loading Tokenizer of Pretrained Model**","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:27:21.339953Z","iopub.execute_input":"2024-05-04T12:27:21.340342Z","iopub.status.idle":"2024-05-04T12:27:22.328943Z","shell.execute_reply.started":"2024-05-04T12:27:21.340311Z","shell.execute_reply":"2024-05-04T12:27:22.328173Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1c25f2637c542458fa4faa4f1d63df7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f87d60314e9411d9234ddaee1ea412e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3106e2af4e924c878935768a17b27d9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082f2b6761404d4982fc94f816d2fa7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae0dc954871a4c709139613346447be7"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Configuration for Low-Rank Adaptation (LoRA)**","metadata":{}},{"cell_type":"code","source":"peft_params = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:27:27.158683Z","iopub.execute_input":"2024-05-04T12:27:27.159399Z","iopub.status.idle":"2024-05-04T12:27:27.163667Z","shell.execute_reply.started":"2024-05-04T12:27:27.159366Z","shell.execute_reply":"2024-05-04T12:27:27.162672Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Setting up parameters**","metadata":{}},{"cell_type":"code","source":"training_params = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:28:41.451371Z","iopub.execute_input":"2024-05-04T12:28:41.451764Z","iopub.status.idle":"2024-05-04T12:28:41.459655Z","shell.execute_reply.started":"2024-05-04T12:28:41.451721Z","shell.execute_reply":"2024-05-04T12:28:41.458627Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Setting up a trainer for Supervised Fine-Tuning (SFT)**","metadata":{}},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_params,\n    dataset_text_field=\"text\",\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_params,\n    packing=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:28:44.228992Z","iopub.execute_input":"2024-05-04T12:28:44.230217Z","iopub.status.idle":"2024-05-04T12:28:56.115256Z","shell.execute_reply.started":"2024-05-04T12:28:44.230150Z","shell.execute_reply":"2024-05-04T12:28:56.114357Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c30eb4367584a64a635d065effd7c84"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:29:04.425772Z","iopub.execute_input":"2024-05-04T12:29:04.426145Z","iopub.status.idle":"2024-05-04T12:55:41.017283Z","shell.execute_reply.started":"2024-05-04T12:29:04.426115Z","shell.execute_reply":"2024-05-04T12:55:41.016071Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 26:04, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.467300</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.433300</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.303800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.344000</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.395900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=125, training_loss=1.3888657836914062, metrics={'train_runtime': 1595.6573, 'train_samples_per_second': 0.627, 'train_steps_per_second': 0.078, 'total_flos': 8971066649149440.0, 'train_loss': 1.3888657836914062, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.tokenizer.save_pretrained(new_model)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T12:58:23.543823Z","iopub.execute_input":"2024-05-04T12:58:23.544231Z","iopub.status.idle":"2024-05-04T12:58:23.813607Z","shell.execute_reply.started":"2024-05-04T12:58:23.544192Z","shell.execute_reply":"2024-05-04T12:58:23.812511Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('llama-2-7b-chat-guanaco/tokenizer_config.json',\n 'llama-2-7b-chat-guanaco/special_tokens_map.json',\n 'llama-2-7b-chat-guanaco/tokenizer.model',\n 'llama-2-7b-chat-guanaco/added_tokens.json',\n 'llama-2-7b-chat-guanaco/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"**Checking Plots on Tensorboard**","metadata":{}},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir results/runs","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:00:24.633836Z","iopub.execute_input":"2024-05-04T13:00:24.634235Z","iopub.status.idle":"2024-05-04T13:00:33.175823Z","shell.execute_reply.started":"2024-05-04T13:00:24.634201Z","shell.execute_reply":"2024-05-04T13:00:33.174924Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"from tensorboard import notebook\nlog_dir = \"results/runs\"\nnotebook.start(\"--logdir {} --port 4000\".format(log_dir))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:01:27.634349Z","iopub.execute_input":"2024-05-04T13:01:27.635279Z","iopub.status.idle":"2024-05-04T13:01:32.655891Z","shell.execute_reply.started":"2024-05-04T13:01:27.635239Z","shell.execute_reply":"2024-05-04T13:01:32.654930Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n          const url = new URL(\"/\", window.location);\n          const port = 4000;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n# Run text generation pipeline with our next model\nprompt = \"Who is Leonardo Da Vinci?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:02:47.396481Z","iopub.execute_input":"2024-05-04T13:02:47.397385Z","iopub.status.idle":"2024-05-04T13:03:19.859082Z","shell.execute_reply.started":"2024-05-04T13:02:47.397347Z","shell.execute_reply":"2024-05-04T13:03:19.857964Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] Who is Leonardo Da Vinci? [/INST] Leonardo da Vinci (1452-1519) was an Italian polymath, artist, inventor, and scientist. He is widely considered one of the greatest painters of all time, and his inventions and designs were centuries ahead of his time. He is known for his famous works such as the Mona Lisa, The Last Supper, and Vitruvian Man. He also made significant contributions to engineering, anatomy, and mathematics. Da Vinci was a true Renaissance man, and his legacy continues to inspire and influence people around the world.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n\n# Run text generation pipeline with our next model\nprompt = \"What is generative AI\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:04:07.501341Z","iopub.execute_input":"2024-05-04T13:04:07.502107Z","iopub.status.idle":"2024-05-04T13:05:00.482241Z","shell.execute_reply.started":"2024-05-04T13:04:07.502072Z","shell.execute_reply":"2024-05-04T13:05:00.481109Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<s>[INST] What is generative AI [/INST] Generative AI is a type of artificial intelligence that can generate new content, such as text, images, or music, based on patterns and trends it has learned from existing data.\n\nGenerative AI models are trained on large datasets of existing content, such as text, images, or audio. They use this training data to learn patterns and trends, and then use these patterns to generate new content that is similar to the training data.\n\nThere are several different types of generative AI models, including:\n\n1. Generative adversarial networks (GANs): GANs consist of two neural networks that are trained together. One network generates new content, while the other network evaluates the generated content and provides feedback to the first network.\n2. Variational autoencoders (VAEs): VAEs are neural networks that are trained to reconstruct existing content.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:16:18.691892Z","iopub.execute_input":"2024-05-04T13:16:18.692832Z","iopub.status.idle":"2024-05-04T13:16:18.697122Z","shell.execute_reply.started":"2024-05-04T13:16:18.692791Z","shell.execute_reply":"2024-05-04T13:16:18.696192Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-06T11:22:28.049080Z","iopub.execute_input":"2024-05-06T11:22:28.050050Z","iopub.status.idle":"2024-05-06T11:22:28.055019Z","shell.execute_reply.started":"2024-05-06T11:22:28.050010Z","shell.execute_reply":"2024-05-06T11:22:28.054091Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}